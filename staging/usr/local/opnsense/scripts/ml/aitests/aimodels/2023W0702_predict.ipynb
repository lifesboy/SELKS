{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QDM3MYoiDuz5",
    "tags": []
   },
   "source": [
    "# 1.Sử dụng các checkpoint đã huấn luyện để đoán nhận dữ liệu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zcq-6tysI-MR"
   },
   "source": [
    "docs lib: https://keras.io/api/layers/recurrent_layers/lstm/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Nhập tên các bộ dữ liệu đoán nhận\n",
    "# là bộ dữ liệu hiện tại, được tạo trong lần đoán nhận này (tên file là lần đoán nhận này)\n",
    "# sẽ trộn cả 2 bộ để đem ra đoán, nếu muốn đoán nhận từng bộ riêng lẻ thì comment lại bộ khác\n",
    "# dùng model hiện tại để doán nhận bộ dữ liệu hiện tại => 2 bộ dưới là 2 bộ dữ liệu hiện tại\n",
    "L_source = \",\".join(map(lambda x: f\"/cic/dataset/normalized_labeled/{x}/\", [\n",
    "    'nsm-2023w07-ftp-01-label',\n",
    "    'nsm-2023w07-dos-02-label',\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Nhập tên các checkpoint\n",
    "# dòng đầu tiên, 2023W0702, là checkpoint hiện tại\n",
    "# dòng thứ 2 trở đi, 2023W0701 ...., là các checkpoint quá khứ để đoán dữ liệu hiện tại là 2023W0702\n",
    "# mỗi dòng, checkpoint là một model version được tải lên để đoán nhận các bộ dữ liệu L_source ở bên trên.\n",
    "checkpoints = [\n",
    "    '2023W0702',\n",
    "    '2023W0701'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Z2wMYO-U5E0",
    "tags": []
   },
   "source": [
    "# 2.PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lsNwxuQyVbua",
    "outputId": "7d50c9d1-980c-4a6a-ca3d-256389399a2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "git version 2.20.1\n",
      "Python 2.7.16\n",
      "ray, version 1.13.0\n",
      "\u001b[0mtf version:  2.7.0\n",
      "tf.keras version: 2.7.0\n",
      "Found GPU at: /device:GPU:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-20 17:11:37.787624: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-20 17:11:39.945489: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /device:GPU:0 with 13348 MB memory:  -> device: 0, name: NVIDIA A16, pci bus id: 0000:3f:00.0, compute capability: 8.6\n",
      "2023-02-20 17:11:39.946704: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /device:GPU:1 with 13348 MB memory:  -> device: 1, name: NVIDIA A16, pci bus id: 0000:40:00.0, compute capability: 8.6\n",
      "2023-02-20 17:11:39.948159: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /device:GPU:2 with 13348 MB memory:  -> device: 2, name: NVIDIA A16, pci bus id: 0000:41:00.0, compute capability: 8.6\n",
      "2023-02-20 17:11:39.949169: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /device:GPU:3 with 13348 MB memory:  -> device: 3, name: NVIDIA A16, pci bus id: 0000:42:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "#@title Check version vs GPU\n",
    "!git --version\n",
    "!python --version\n",
    "!ray --version\n",
    "\n",
    "import tensorflow as tf\n",
    "print('tf version: ', tf.__version__)\n",
    "print('tf.keras version:', tf.keras.__version__)\n",
    "\n",
    "import sys\n",
    "sys.version\n",
    "\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  print('GPU device not found')\n",
    "else:\n",
    "  print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H2mllWoXJwv6"
   },
   "outputs": [],
   "source": [
    "#@title Import Libraries\n",
    "!mkdir -p /cic/images/\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"/usr/local/opnsense/scripts/ml\")\n",
    "\n",
    "import json\n",
    "import ray\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "from ray.data import Dataset\n",
    "from ray.data.aggregate import Count\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "\n",
    "import common\n",
    "from anomaly_normalization import LABEL\n",
    "from aitests.testutils import show_scattered_4d, show_weights, show_4d_imgs, IMG, read_csv_in_dir\n",
    "\n",
    "run, client = common.init_experiment(name='notebook')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XTorwf7eXWkU",
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "# 3.INPUT\n",
    "Let's generate a sample input with time dimension as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4QW42m7LCHtO",
    "outputId": "1417d69e-0cf5-4c43-943f-00d357111f5f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#@title Generate an input sequence\n",
    "n_timesteps_in = 100  #@param {type:\"integer\"}\n",
    "n_features = 79   #@param {type:\"integer\"}\n",
    "\n",
    "L_data: Dataset = read_csv_in_dir(L_source)\n",
    "L_count: DataFrame = L_data.groupby(LABEL).aggregate(Count()).to_pandas()\n",
    "\n",
    "features = ['ack_flag_cnt', 'active_max', 'active_mean', 'active_min', 'active_std', 'bwd_blk_rate_avg', 'bwd_byts_b_avg', 'bwd_header_len', 'bwd_iat_max', 'bwd_iat_mean', 'bwd_iat_min', 'bwd_iat_std', 'bwd_iat_tot', 'bwd_pkt_len_max', 'bwd_pkt_len_mean', 'bwd_pkt_len_min', 'bwd_pkt_len_std', 'bwd_pkts_b_avg', 'bwd_pkts_s', 'bwd_psh_flags', 'bwd_seg_size_avg', 'bwd_urg_flags', 'cwe_flag_count', 'down_up_ratio', 'dst_port', 'ece_flag_cnt', 'fin_flag_cnt', 'flow_byts_s', 'flow_duration', 'flow_iat_max', 'flow_iat_mean', 'flow_iat_min', 'flow_iat_std', 'flow_pkts_s', 'fwd_act_data_pkts', 'fwd_blk_rate_avg', 'fwd_byts_b_avg', 'fwd_header_len', 'fwd_iat_max', 'fwd_iat_mean', 'fwd_iat_min', 'fwd_iat_std', 'fwd_iat_tot', 'fwd_pkt_len_max', 'fwd_pkt_len_mean', 'fwd_pkt_len_min', 'fwd_pkt_len_std', 'fwd_pkts_b_avg', 'fwd_pkts_s', 'fwd_psh_flags', 'fwd_seg_size_avg', 'fwd_seg_size_min', 'fwd_urg_flags', 'idle_max', 'idle_mean', 'idle_min', 'idle_std', 'init_bwd_win_byts', 'init_fwd_win_byts', 'pkt_len_max', 'pkt_len_mean', 'pkt_len_min', 'pkt_len_std', 'pkt_len_var', 'pkt_size_avg', 'protocol', 'psh_flag_cnt', 'rst_flag_cnt', 'src_port', 'subflow_bwd_byts', 'subflow_bwd_pkts', 'subflow_fwd_byts', 'subflow_fwd_pkts', 'syn_flag_cnt', 'tot_bwd_pkts', 'tot_fwd_pkts', 'totlen_bwd_pkts', 'totlen_fwd_pkts', 'urg_flag_cnt']\n",
    "features = features[0: n_features]\n",
    "Lpadding_features = sorted(list(set(features) - set(L_data.schema(fetch_if_missing=True).names)))\n",
    "\n",
    "total_size = int(L_count.sum()['count()']) // n_timesteps_in\n",
    "predict_size = total_size\n",
    "print ('features=', features)\n",
    "print ('Lpadding_features=', Lpadding_features)\n",
    "print ('total_size = ', total_size)\n",
    "print ('predict_size = ', predict_size)\n",
    "\n",
    "\n",
    "L_predict = DataFrame.from_records(L_data.take(predict_size  * n_timesteps_in))\n",
    "L_predict[Lpadding_features] = 0\n",
    "LX_predict = L_predict[features].to_numpy().reshape(predict_size, n_timesteps_in, n_features)\n",
    "Ly_predict = L_predict[[LABEL]].to_numpy().reshape((predict_size, n_timesteps_in))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "id": "Km_Qgxukfqh_",
    "outputId": "0d1b5c2f-4843-4adf-805f-e17c990fa279"
   },
   "outputs": [],
   "source": [
    "L_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WCOnndilg9V_",
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "## Data preview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6XJlWAQyZn1O",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### L_train preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "Qv5w47hMZn1a",
    "outputId": "f6beb770-8728-42cc-bcf6-851e2669dd59"
   },
   "outputs": [],
   "source": [
    "L_predict[[LABEL, *features]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "id": "c4acLM-UZn1a",
    "outputId": "ef05faf7-0629-4add-81c0-ac0cf5ab295e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "L_predict[[LABEL, *features]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "CFoa8dY4fDy9",
    "outputId": "2f037fa0-51ed-4251-c843-96be01e1a173"
   },
   "outputs": [],
   "source": [
    "DataFrame.from_records(LX_predict[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "id": "Onxu2ezQfHCY",
    "outputId": "f53725b7-7ce9-4336-f177-9c55a1b1b1b9"
   },
   "outputs": [],
   "source": [
    "DataFrame.from_records(LX_predict[0]).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "1Mt42r_2fMWT",
    "outputId": "bcd77014-ff64-4408-b75a-c71479b85007"
   },
   "outputs": [],
   "source": [
    "DataFrame.from_records(Ly_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "id": "LUQlDQtefQd3",
    "outputId": "7dcaf211-3194-44af-f343-8d031fc74139"
   },
   "outputs": [],
   "source": [
    "DataFrame.from_records(Ly_predict).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S94Adh2TYUb9",
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "## Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Oq1n8cmoq6cY"
   },
   "outputs": [],
   "source": [
    "#@title create data IMG\n",
    "IMG['LX_predict'], IMG['Ly_predict'] = ray.get([\n",
    "    show_scattered_4d.remote(LX_predict, 'LX_predict'),\n",
    "    show_scattered_4d.remote(Ly_predict, 'Ly_predict'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 939
    },
    "id": "g2yw-ZAinGMl",
    "outputId": "14d296ee-e7d1-460a-84f2-58ec62dfb4e8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#@title overview featured vs normalized data IMG\n",
    "\n",
    "show_4d_imgs(['LX_predict','Ly_predict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BqLmyIPxVAs7",
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "# 4.INTRODUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oUGKsAXAzkpC",
    "tags": []
   },
   "source": [
    "# 5.LSTM Anomaly State management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_11zzhFxwACk"
   },
   "source": [
    "## 5.1.Model layers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold(num) là ngưỡng quyết định kết quả dữ đoán là anomaly hay benign, ví dụ: 0.5 ở đây là\n",
    "# nếu kết quả dự đoán > 0.5 thì xem là anomaly, còn lại là benign, kết quả dự đoán của 1 flow\n",
    "def threshold(num):\n",
    "    return 1 if num > 0.5 else 0\n",
    "\n",
    "def infer_by_checkpoint(checkpoint, name='model6'):\n",
    "    model = keras.models.load_model(f\"/usr/local/opnsense/scripts/ml/aicheckpoints/{checkpoint}/{name}\")\n",
    "    Ly_predict_predicted=model.predict(LX_predict)\n",
    "    predicted = np.vectorize(threshold)(Ly_predict_predicted)\n",
    "    \n",
    "    actual = predicted.ravel()\n",
    "    expected = Ly_predict.ravel()\n",
    "    anomaly_detected = anomaly_incorrect = benign_detected = benign_incorrect = 0\n",
    "    for i in range(0, len(actual)):\n",
    "        anomaly_detected += actual[i] == expected[i] == 1\n",
    "        anomaly_incorrect += (actual[i] == 0) & (expected[i] == 1)\n",
    "        benign_detected += actual[i] == expected[i] == 0\n",
    "        benign_incorrect += (actual[i] == 1) & (expected[i] == 0)\n",
    "    \n",
    "    df = DataFrame.from_dict({\n",
    "        'checkpoint': [checkpoint],\n",
    "        'anomaly_detected': [anomaly_detected],\n",
    "        'anomaly_incorrect': [anomaly_incorrect],\n",
    "        'benign_detected': [benign_detected],\n",
    "        'benign_incorrect': [benign_incorrect],\n",
    "        'detected': [anomaly_detected + benign_detected],\n",
    "        'incorrect': [anomaly_incorrect + benign_incorrect],\n",
    "        'detected_rate': [(anomaly_detected + benign_detected) / len(actual)],\n",
    "        'incorrect_rate': [(anomaly_incorrect + benign_incorrect) / len(actual)],\n",
    "    })    \n",
    "    print(df.to_string())\n",
    "\n",
    "    [IMG['Ly_predict_predicted']] = ray.get([\n",
    "        show_scattered_4d.remote(Ly_predict_predicted, \"Ly_predict_predicted\"),\n",
    "    ])\n",
    "    show_4d_imgs(['LX_predict','Ly_predict','Ly_predict_predicted'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uonnep0TYzaD"
   },
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OixGxky67SPY",
    "tags": []
   },
   "source": [
    "# 6.LSTM Anomaly model (Primary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YNRzl5SV7SPk"
   },
   "source": [
    "## 6.3.Infer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataFrame()\n",
    "for c in checkpoints:\n",
    "    df = pd.concat([df, infer_by_checkpoint(c)], axis=0, ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "QDM3MYoiDuz5",
    "ybFX1kIUY3rJ",
    "BqLmyIPxVAs7",
    "X_PcZecHAbPg",
    "DDDDpZ6Zzz5u",
    "t6cq5X6sz_Jt",
    "xinBM3ht0G2x",
    "D3_1jAhZTTh1",
    "oUGKsAXAzkpC",
    "OixGxky67SPY",
    "twmR3M4Q7SPi",
    "sl9ubzArNGbX",
    "PADcXjnyMb9q",
    "hCz4CC4nXTa2",
    "Iwr0P8eF7gcW",
    "ODGPXYwL7gcb",
    "Svib5ngYaMSS"
   ],
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
